{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"JmDGFG2--t5z","executionInfo":{"status":"ok","timestamp":1649319460186,"user_tz":300,"elapsed":580,"user":{"displayName":"Gabriel González Sahagún","userId":"12497170045078186877"}}},"outputs":[],"source":["# !git clone https://github.com/GabrielGlzSa/ModelCompression.git\n","# %cd ModelCompression/\n","# !git checkout --track origin/CompressionV2\n","# !pip install Pillow \\\n","#     h5py \\\n","#     keras_preprocessing \\\n","#     matplotlib \\\n","#     mock \\\n","#     numpy \\\n","#     scipy \\\n","#     sklearn \\\n","#     pandas \\\n","#     future \\\n","#     portpicker \\\n","#     enum34 \\\n","#     tensorflow==2.6.2 \\\n","#     tensorflow_datasets==4.0.1\\\n","#     tensorflow_transform\\\n","#     tensorboard_plugin_profile\\\n","#     seaborn\\\n","#     pyparsing==2.4.7\\\n","#     tf_agents \\\n","#     tensorflow-model-optimization\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1823,"status":"ok","timestamp":1649319462727,"user":{"displayName":"Gabriel González Sahagún","userId":"12497170045078186877"},"user_tz":300},"id":"iDwFWUHjSfoe","outputId":"4b211ce4-d4bb-406a-a43f-999c76c2f4f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/Colab Projects\n"," Adadeep.ipynb   \u001b[0m\u001b[01;34mdata\u001b[0m/                     \u001b[01;34mModelCompression\u001b[0m/\n"," \u001b[01;34mcheckpoints\u001b[0m/   'DQN Optimization.ipynb'  'Test compressors.ipynb'\n"]}],"source":["from google.colab import drive\n","import sys\n","\n","drive.mount('/content/drive/')\n","%cd ./drive/MyDrive/Colab Projects/\n","%ls\n","\n","sys.path.insert(0, './ModelCompression')\n","dataset = 'mnist'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4491,"status":"ok","timestamp":1649319467216,"user":{"displayName":"Gabriel González Sahagún","userId":"12497170045078186877"},"user_tz":300},"id":"VtFjvWDHDi7s"},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import logging\n","import pandas as pd\n","from IPython.display import clear_output\n","from utils import load_dataset\n","from CompressionTechniques import *\n","from replay_buffer import ReplayBuffer\n","from environments import *\n","from custom_layers import ROIEmbedding, MLPConvV1\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s -%(levelname)s - %(funcName)s -  %(message)s')"]},{"cell_type":"code","source":["# kernel_size = (3,3)\n","# channels = 3\n","# bases = 4\n","# filters = 32\n","# fh, fw = kernel_size\n","# S = np.random.random(size=(channels, bases, filters))\n","# Q = np.random.random(size=(channels, fh, fw, bases))\n","# P = np.random.random(size=(channels, channels))\n","# v1 = SparseConvolution2D(kernel_size=kernel_size,\n","#                            filters=filters,\n","#                            PQS=[P, Q, S],\n","#                            bases=bases)\n","\n","# imgs = tf.constant(np.random.randint(0, 255, size=(4,32,32,3)).astype(np.float32))\n","# %timeit v1(imgs)"],"metadata":{"id":"mzVWlzxlH2Yg","executionInfo":{"status":"ok","timestamp":1649319467217,"user_tz":300,"elapsed":4,"user":{"displayName":"Gabriel González Sahagún","userId":"12497170045078186877"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9RqwdKCD1we"},"source":[""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Qdxi8xTrIx0Z","outputId":"c02f1d3c-76ee-4db8-d07d-0e8101c08859","executionInfo":{"status":"error","timestamp":1649319535715,"user_tz":300,"elapsed":68502,"user":{"displayName":"Gabriel González Sahagún","userId":"12497170045078186877"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["2022-04-07 08:17:47,441 -INFO - read_from_directory -  Load dataset info from ./data/mnist/3.0.1\n","2022-04-07 08:17:47,463 -INFO - read_from_directory -  Field info.citation from disk and from code do not match. Keeping the one from code.\n","2022-04-07 08:17:47,469 -INFO - download_and_prepare -  Reusing dataset mnist (./data/mnist/3.0.1)\n","2022-04-07 08:17:47,482 -INFO - as_dataset -  Constructing tf.data.Dataset for split ['train[:80%]', 'train[80%:]', 'test'], from ./data/mnist/3.0.1\n","2022-04-07 08:17:49,029 -INFO - read_from_directory -  Load dataset info from ./data/mnist/3.0.1\n","2022-04-07 08:17:49,042 -INFO - read_from_directory -  Field info.citation from disk and from code do not match. Keeping the one from code.\n","2022-04-07 08:17:49,049 -INFO - download_and_prepare -  Reusing dataset mnist (./data/mnist/3.0.1)\n","2022-04-07 08:17:49,065 -INFO - as_dataset -  Constructing tf.data.Dataset for split ['train[:80%]', 'train[80%:]', 'test'], from ./data/mnist/3.0.1\n","2022-04-07 08:17:50,792 -INFO - compress_layer -  Searching for layer: conv2d_1\n","2022-04-07 08:17:50,810 -INFO - find_pqs -  Searching for matrix P.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:17:50,988 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:17:51,138 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n","2022-04-07 08:17:55,522 -INFO - find_pqs -  Epoch 0 of RxP Loss: 76.98979949951172\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:17:55,597 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:17:55,796 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n","2022-04-07 08:18:00,714 -INFO - find_pqs -  Searching for matrices Q and S.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:18:00,858 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:18:00,973 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n","2022-04-07 08:18:06,018 -INFO - find_pqs -  Epoch 0 Loss: 11.547910690307617\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:18:06,115 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:18:06,336 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n","2022-04-07 08:18:10,992 -INFO - find_pqs -  Matrix P has shape (32, 32)\n","2022-04-07 08:18:11,000 -INFO - find_pqs -  Matrix Q has shape (32, 3, 3, 4)\n","2022-04-07 08:18:11,005 -INFO - find_pqs -  Matrix S has shape (32, 4, 32)\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:18:11,886 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stderr","text":["2022-04-07 08:18:12,145 -WARNING - _fallback_converter -  Using a while_loop for converting Slice\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","  88/1500 [>.............................] - ETA: 6:42 - loss: 1.8747 - sparse_categorical_accuracy: 0.9119"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-0f73c55cca76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-0f73c55cca76>\u001b[0m in \u001b[0;36mmake_env\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     79\u001b[0m     compressor = SparseConvolutionCompression(model=model, dataset=train_ds,\n\u001b[1;32m     80\u001b[0m                                 optimizer=optimizer, loss=loss_object, metrics=train_metric, bases=4, input_shape=input_shape)\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv2d_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab Projects/ModelCompression/CompressionTechniques.py\u001b[0m in \u001b[0;36mcompress_layer\u001b[0;34m(self, layer_name, iterations)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def make_env(dataset):\n","    train_ds, val_ds, test_ds, input_shape, num_classes = load_dataset(dataset)\n","    train_ds, valid_ds, test_ds, input_shape, num_classes = load_dataset(dataset)\n","\n","    model_path = './data/full_model/test_'+dataset\n","    optimizer = tf.keras.optimizers.Adam()\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","    train_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n","    try:\n","      model = tf.keras.models.load_model(model_path, compile=True)\n","    except OSError:\n","      \n","      model = tf.keras.Sequential([tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_0',\n","                                                          input_shape=input_shape),\n","                                   tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_1'),\n","                                   tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_2'),\n","                                   tf.keras.layers.MaxPool2D((2, 2), 2),\n","                                   tf.keras.layers.Flatten(),\n","                                   tf.keras.layers.Dense(128, activation='relu', name='dense_0'),\n","                                   tf.keras.layers.Dense(128, activation='relu', name='dense_1'),\n","                                   tf.keras.layers.Dense(num_classes, activation='softmax', name='dense_softmax')\n","                                   ])\n","      model.compile(optimizer=optimizer, loss=loss_object, metrics=train_metric)\n","      model.fit(train_ds, epochs=5, validation_data=valid_ds)\n","      model.save(model_path)\n","\n","    parameters = {}\n","    parameters['DeepCompression'] = {'layer_name': 'dense_0', 'threshold': 0.001}\n","    parameters['ReplaceDenseWithGlobalAvgPool'] = {'layer_name': 'dense_1'}\n","    parameters['InsertDenseSVD'] = {'layer_name': 'dense_0', 'units': 16}\n","    parameters['InsertDenseSVDCustom'] = {'layer_name': 'dense_0', 'units': 16}\n","    parameters['InsertDenseSparse'] = {'layer_name': 'dense_0', 'verbose': True, 'units': 16}\n","    parameters['InsertSVDConv'] = {'layer_name': 'conv2d_1', 'units': 8}\n","    parameters['DepthwiseSeparableConvolution'] = {'layer_name': 'conv2d_1'}\n","    parameters['FireLayerCompression'] = {'layer_name': 'conv2d_1'}\n","    # parameters['MLPCompression'] = {'layer_name': 'conv2d_1'}\n","    parameters['SparseConnectionsCompression'] = {'layer_name': 'conv2d_1', 'epochs': 20,\n","                                                  'target_perc': 0.75, 'conn_perc_per_epoch': 0.1}\n","    # compressor = ReplaceDenseWithGlobalAvgPool(model=model, dataset=train_ds,\n","    #                                            optimizer=optimizer, loss=loss_object, metrics=train_metric)\n","    # compressor.compress_layer()\n","\n","\n","    # compressor = InsertDenseSVD(model=model, dataset=train_ds,\n","    #                             optimizer=optimizer, loss=loss_object, metrics=train_metric, fine_tune=False)\n","    # compressor.compress_layer('dense_1', units=32)\n","\n","\n","    # compressor = InsertDenseSparse(model=model, dataset=train_ds,\n","    #                             optimizer=optimizer, loss=loss_object, metrics=train_metric)\n","    # compressor.compress_layer('dense_1', verbose=True)\n","\n","\n","    # compressor = InsertSVDConv(model=model, dataset=train_ds,\n","    #                             optimizer=optimizer, loss=loss_object, metrics=train_metric)\n","    # compressor.compress_layer('conv2d_1')\n","\n","    # compressor = DepthwiseSeparableConvolution(model=model, dataset=train_ds,\n","    #                             optimizer=optimizer, loss=loss_object, metrics=train_metric)\n","    # compressor.compress_layer('conv2d_1')\n","\n","    # compressor = FireLayerCompression(model=model, dataset=train_ds,\n","    #                                   optimizer=optimizer, loss=loss_object, metrics=train_metric)\n","    # compressor.compress_layer('conv2d_1')\n","\n","    # compressor = MLPCompression(model=model, dataset=train_ds,\n","    #                             optimizer=optimizer, loss=loss_object, metrics=train_metric)\n","    # compressor.compress_layer('conv2d_1')\n","\n","    # population=20,generations=100 takes 3 hours and 40 minutes\n","    # compressor = SparseConnectionsCompressionCustom(model=model,\n","    #                                                 dataset=train_ds,\n","    #                                                 optimizer=optimizer,\n","    #                                                 loss=loss_object,\n","    #                                                 metrics=train_metric)\n","    # compressor.compress_layer('conv2d_1', epochs=10)\n","\n","    # RAM OOM in training loop.\n","    compressor = SparseConvolutionCompression(model=model, dataset=train_ds,\n","                                optimizer=optimizer, loss=loss_object, metrics=train_metric, bases=4, input_shape=input_shape)\n","    compressor.compress_layer('conv2d_1', iterations=2)\n","\n","    new_model = compressor.get_model()\n","    for layer in new_model.layers:\n","        print(layer)\n","\n","\n","make_env(dataset)"]},{"cell_type":"code","source":["%tensorboard --logdir data/logdir/tfboard_v1"],"metadata":{"id":"GaYszr6FfXL7","executionInfo":{"status":"aborted","timestamp":1649319535715,"user_tz":300,"elapsed":2,"user":{"displayName":"Gabriel González Sahagún","userId":"12497170045078186877"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Test compressors.ipynb","provenance":[],"authorship_tag":"ABX9TyMad9ua7IxZlq3VjAmTHS8g"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}